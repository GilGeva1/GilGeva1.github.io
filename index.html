<!DOCTYPE html>
<html>
<head>
<!--     <title>Binaural sound source localization using a hybrid time and frequency domain model</title> -->
	<title>Binaural sound source localization <br> using a hybrid time and frequency domain model</title>

    <link rel="icon" href="Github_images/NEU-KU100.jpg" type="image/png">
    <style>
        body {
            font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
            font-weight: 300;
            font-size: 18px;
            margin-left: auto;
            margin-right: auto;
            width: 1100px;
        }

        h1 {
            font-size: 32px;
            font-weight: 300;
        }

        .disclaimerbox {
            background-color: #eee;
            border: 1px solid #eeeeee;
            border-radius: 10px;
            -moz-border-radius: 10px;
            -webkit-border-radius: 10px;
            padding: 20px;
        }

        video.header-vid,
        img.header-img,
        img.rounded {
            height: 140px;
            border: 1px solid black;
            border-radius: 10px;
            -moz-border-radius: 10px;
            -webkit-border-radius: 10px;
        }

        a:link,
        a:visited {
            color: #1367a7;
            text-decoration: none;
        }

        a:hover {
            color: #208799;
        }

        td.dl-link {
            height: 160px;
            text-align: center;
            font-size: 22px;
        }
        /* Center the citation block */
		#citation {
		  text-align: left;
		  display: inline-block;
		  margin: 0 auto;
		}
		
		/* Move the author names to the left */
		/* Move the author names to the left */
		#citation pre {
         	  font-size: 15px; /* Set the font size to 14px or any other size you prefer */
		}
		
		/* Center the images */
		img {
		  display: block;
		  margin: 0 auto;
		}

        /* Add your other styles here */
    </style>
</head>
<body>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">google.load("jquery", "1.3.2");</script>

    <br>
    <center>
        <span style="font-size:36px">Binaural sound source localization using a hybrid time and frequency domain model</span><br>

	<br>
        <table align="center" width="550px">
            <tr>
                <td align="center" width="100px">
                    <center>
                        <span style="font-size:24px">Gil Geva</span>
                    </center>
                </td>
                <td align="center" width="100px">
                    <center>
                        <span style="font-size:24px">Yacov Hel-Or</span>
                    </center>
                </td>
            </tr>
        </table><br>

	<table align="center" width="650px">
            <tr>
                <td align="center" width="120px">
                    <center>
                        <span style="font-size:24px"><a href='https://github.com/GilGeva1/GilGeva1.github.io/blob/9bdadd1180b4240a2ee7808bf441a5f67dbbf0c8/ICASSP_2024%20-%20Gil%20Geva.pdf'>[Paper]</a></span>
                    </center>
                </td>

		<td align="center" width="120px">
                    <center>
                        <span style="font-size:24px"><a href='https://github.com/GilGeva1/GilGeva1.github.io/blob/e7f0a43ae3d6a60ad371e03d69e35324e68777c5/Thesis%20-%20Gil%20Geva.pdf'>[Thesis]</a></span>
                    </center>
                </td>
		    
                <td align="center" width="120px">
                    <center>
                        <span style="font-size:24px"><a href='https://github.com/GilGeva1/GilGeva1.github.io'>[GitHub]</a></span><br>
                    </center>
                </td>

		<td align="center" width="120px">
                    <center>
                        <span style="font-size:24px"><a href='Thesis_Final.py.zip'>[Code]</a></span><br>
                    </center>
                </td>
            </tr>
        </table>
    </center>

    <hr>

    <center>
        <tr>
            <td>
                <img width="300" alt="image" src="Github_images/NEU-KU100.jpg">
            </td>
        </tr>
    </center>

    <br>

    <hr>
    <table align="center" width="850px">
        <center>
            <h1>Introduction</h1>
        </center>
        <tr>
            <td>
                <p>We are pleased to share our research on "Binaural sound source localization using a hybrid time and frequency domain model".</p>

                <p>The study was conducted as part of a thesis for Reichman University in collaboration with IRCAM Institute.</p>

                <p>It has been accepted for presentation at the IEEE conference ICASSP 2024.</p>

                <p>Included in this repository are an overview of the research, images illustrating data collection at Reichman University and IRCAM Institute, and a description of the model architecture.</p>
			
		<p>It also contains HRIR files for each ear of every speaker in IRCAM, a .py file for the code and data processing, the thesis document and defense presentation, a conference paper, and a reference citation.</p>
            </td>
        </tr>
    </table>

            </td>
        </tr>
    </table>

	
	
    <br>

	
    <hr>
    <center>
        <h1>Recording Studios</h1>
        <p align="center">
            <img width="800" alt="image" src="Github_images/recording_studios.png">
        </p>
    </center>
    </table>
    <br>

    <hr>

    <table align="center" width="850px">
        <center>
            <h1>Abstract</h1>
        </center>
        <tr>
            <td>
		<p>Sound source localization plays a foundational role in auditory perception, enabling both human and machines to determine the sound source location. Traditional sound localization methods often rely on manually crafted features and simplified conditions, which limit their applicability in real-world situations.</p>
		
		<p>Accurate sound localization holds vital importance across diverse applications, spanning robotics, virtual reality, human-computer interactions, and medical devices. This significance is particularly amplified for individuals with cochlear implants (CI), who confront significant challenges in perceiving the direction of sound sources.</p>
		
		<p>Previous research focused on extensive microphone arrays in the frontal plane, which exhibit accuracy and robustness limitations when employing small microphone arrays. These sound localization techniques are also impractical for CI users due to size and weight constraints, and the need for full-sphere localization capabilities.</p>
		
		<p>This research introduces a new approach to sound source localization using head-related transfer function (HRTF) characteristics, from raw data, in both the time and frequency domains. Furthermore, it advances binaural sound localization by extending its capabilities from a 180-degree range to a full-sphere context.</p>
		
		<p>The proposed approach introduces an end-to-end Deep-Learning (DL) hybrid model, that integrates spectrogram and temporal domain insights via parallel channels. The performance of our proposed hybrid model, surpasses the current state-of-the-art results. Specifically, it boasts an average angular error of 0.24 degrees and an average Euclidean distance of 0.01 meters, while the known state-of-the-art gives average angular error of 19.07 degrees and average Euclidean distance of 1.08 meters.</p>
		
		<p>This level of accuracy is of paramount importance for a wide range of applications, including robotics, virtual reality, and aiding individuals with CI.</p>
		
		<p>In conclusion, as the field of sound source localization continues to progress, this research contributes to a deeper understanding of auditory perception and offers practical applications within healthcare scenarios.</p>

            </td>
        </tr>
    </table>
    <br>

    <hr>
    <center>
        <h1>Architecture</h1>
        <img width="750" alt="image" src="Github_images/hybrid_arch.jpg">
    </center>
    <br>
    <hr>

    <table align="center" width="450px">
        <tr>
            <center>
                <h1>Citation</h1>
            </center>

            <div id="citation">
		<center>
                <p>If you use our code or model in your research, please cite this paper:</p>
		</center>
                <pre>
@article{geva2024binaural,
      title={Binaural sound source localization using a hybrid time and frequency domain model},
      author={Geva, Gil and Warusfel, Olivier and Dubnov, Shlomo and Dubnov, Tammuz and Amedi, Amir and Hel-Or, Yacov},
      journal={arXiv preprint arXiv:2402.03867},
      year={2024}
}
            <center>
	</div>

	<br>
    	<hr>
            </center>

    <table align="center" width="900px">
        <tr>
            <td width="400px">
                <left>
                    <center>
                        <h1>Acknowledgements</h1>
                        This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
                    </center>
                </left>
            </td>
        </tr>
    </table>

    <br>
</body>
</html>
